{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Using CNN with the Cats vs Dogs Dataset\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RehuHak8kXjI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# skidamo dataset (kao zip fajl) u tmp folderu, a zatim ga otkapujemo u tom istom folderu (Pet images)\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\" \\\n",
        "    -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "local_zip = '/tmp/cats-and-dogs.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsUDUEyVkXlj",
        "outputId": "062e9f23-d2fc-4049-a151-64ed43cb8c3c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-06 21:43:05--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.34.248.153, 2600:1408:c400:168a::317f\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.34.248.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824887076 (787M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
            "\n",
            "/tmp/cats-and-dogs. 100%[===================>] 786.67M   167MB/s    in 4.2s    \n",
            "\n",
            "2023-03-06 21:43:09 (185 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824887076/824887076]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kreiramo funckiju koja ce kreirati neophodne direktorijume\n",
        "def create_train_val_dirs(root_path):\n",
        "\n",
        "  base_dir = root_path\n",
        "  os.makedirs(root_path)\n",
        "\n",
        "  training_dir = os.path.join(base_dir, 'training')\n",
        "  os.makedirs(training_dir)\n",
        "\n",
        "  validation_dir = os.path.join(base_dir, 'validation')\n",
        "  os.makedirs(validation_dir)\n",
        "  \n",
        "  training_cats_dir = os.path.join(training_dir, 'cats')\n",
        "  os.makedirs(training_cats_dir)\n",
        "\n",
        "  training_dogs_dir = os.path.join(training_dir, 'dogs')\n",
        "  os.makedirs(training_dogs_dir)\n",
        "\n",
        "  validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "  os.makedirs(validation_cats_dir)\n",
        "\n",
        "  validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "  os.makedirs(validation_dogs_dir)"
      ],
      "metadata": {
        "id": "sN8VZ4R1llig"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definisemo funkciju koja ce podeliti podatke za trening i validaciju\n",
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "  \n",
        "  # izvlacimo podatke iz SOURCE_DIR\n",
        "  sd = os.listdir(SOURCE_DIR)\n",
        "  # brisemo sve podatke cija je velicina jednaka 0\n",
        "  for fname in sd:\n",
        "    if os.path.getsize(os.path.join(SOURCE_DIR, fname)) <= 0:\n",
        "      print(fname, \"is zero length, so ignoring.\")\n",
        "      sd.remove(fname)\n",
        "  \n",
        "  # definisemo velicinu training i validation seta\n",
        "  training_size = round(len(sd) * SPLIT_SIZE)\n",
        "  validation_size = round(len(sd) * (1 - SPLIT_SIZE))\n",
        "\n",
        "  # shuffle-ujemo podatke \n",
        "  random.sample(sd, len(sd))\n",
        "\n",
        "  # upisujemo podatke u training i validation sample\n",
        "  training_sample = random.sample(sd[:training_size], training_size)\n",
        "  validation_sample = random.sample(sd[training_size:], validation_size)\n",
        "\n",
        "  # upisujemo podatke u odgovarajuce direktorijume\n",
        "  for fname in training_sample:\n",
        "    copyfile(os.path.join(SOURCE_DIR, fname), os.path.join(TRAINING_DIR, fname))\n",
        "\n",
        "  for fname in validation_sample:\n",
        "    copyfile(os.path.join(SOURCE_DIR, fname), os.path.join(VALIDATION_DIR, fname))"
      ],
      "metadata": {
        "id": "v68Ejob1lllG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kreiramo training i validation data generatore\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  \n",
        "  # instanciramo ImageDataGenerator klasu\n",
        "  train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "  # kreiramo training generator\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=10,\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=(150, 150))\n",
        "  \n",
        "  # instanciramo ImageGenerator klasu za validation data\n",
        "  validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "  # kreiramo validation generator\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=10,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(150, 150))\n",
        "  \n",
        "  return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "74k6fyLqllsb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kreiramo model\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "def create_model():\n",
        "\n",
        "  model = tf.keras.models.Sequential([ \n",
        "      # kreiramo prvi Convolution layer\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      \n",
        "      # kreiramo drugi Convolution layer\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "      # kreiramo treci Convolution layer\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "      # pretvaramo matricu u 1-dimenzionalni niz\n",
        "      tf.keras.layers.Flatten(),\n",
        "      # definisemo sloj sa 512 neurona i aktivacionom funkcijom relu\n",
        "      tf.keras.layers.Dense(512, activation='relu'),\n",
        "      # definisemo 1 izlazni neuron sa aktivacioniom funkcijom sigmoid\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "\n",
        "\n",
        "  model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy']) \n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "G1aQHyGwlluu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definisemo root direktorijum\n",
        "root_dir = '/tmp/cats-v-dogs'\n",
        "\n",
        "# ako podaci u direktorijumu vec postoje, obrisi ih (korisceno za potrebe testiranja)\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "  \n",
        "# pozivamo funkciju za kreiranje direktorijuma\n",
        "create_train_val_dirs(root_path=root_dir)\n",
        "\n",
        "# definisemo putanje \n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
        "VALIDATION_DIR = \"/tmp/cats-v-dogs/validation/\"\n",
        "TRAINING_CATS_DIR = os.path.join(TRAINING_DIR, \"cats/\")\n",
        "VALIDATION_CATS_DIR = os.path.join(VALIDATION_DIR, \"cats/\")\n",
        "TRAINING_DOGS_DIR = os.path.join(TRAINING_DIR, \"dogs/\")\n",
        "VALIDATION_DOGS_DIR = os.path.join(VALIDATION_DIR, \"dogs/\")\n",
        "\n",
        "# definisemo split_size\n",
        "split_size = 0.9"
      ],
      "metadata": {
        "id": "almJyCb0ssQf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pozivamo funkciju za podelu podataka\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, VALIDATION_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, VALIDATION_DOGS_DIR, split_size)\n",
        "\n",
        "# pozivamo funkciju za kreiranje generatora\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)\n",
        "\n",
        "# kreiramo model\n",
        "model = create_model()\n",
        "\n",
        "# treniramo model\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvHa8-dKllxD",
        "outputId": "5850d876-fd5e-412b-f280-1ce2cdcbbc0b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "666.jpg is zero length, so ignoring.\n",
            "11702.jpg is zero length, so ignoring.\n",
            "Found 22498 images belonging to 2 classes.\n",
            "Found 2500 images belonging to 2 classes.\n",
            "Epoch 1/15\n",
            "  45/2250 [..............................] - ETA: 1:19 - loss: 0.8535 - accuracy: 0.5311"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/PIL/TiffImagePlugin.py:819: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2250/2250 [==============================] - 110s 44ms/step - loss: 0.5948 - accuracy: 0.6784 - val_loss: 0.5029 - val_accuracy: 0.7532\n",
            "Epoch 2/15\n",
            "2250/2250 [==============================] - 95s 42ms/step - loss: 0.4806 - accuracy: 0.7760 - val_loss: 0.4319 - val_accuracy: 0.8052\n",
            "Epoch 3/15\n",
            "2250/2250 [==============================] - 95s 42ms/step - loss: 0.4108 - accuracy: 0.8179 - val_loss: 0.4224 - val_accuracy: 0.8120\n",
            "Epoch 4/15\n",
            "2250/2250 [==============================] - 97s 43ms/step - loss: 0.3527 - accuracy: 0.8517 - val_loss: 0.4106 - val_accuracy: 0.8168\n",
            "Epoch 5/15\n",
            "2250/2250 [==============================] - 94s 42ms/step - loss: 0.3056 - accuracy: 0.8765 - val_loss: 0.4539 - val_accuracy: 0.8188\n",
            "Epoch 6/15\n",
            "2250/2250 [==============================] - 93s 41ms/step - loss: 0.2678 - accuracy: 0.8960 - val_loss: 0.5312 - val_accuracy: 0.8492\n",
            "Epoch 7/15\n",
            "2250/2250 [==============================] - 95s 42ms/step - loss: 0.2338 - accuracy: 0.9135 - val_loss: 0.4389 - val_accuracy: 0.8324\n",
            "Epoch 8/15\n",
            "2250/2250 [==============================] - 93s 41ms/step - loss: 0.2060 - accuracy: 0.9278 - val_loss: 0.5387 - val_accuracy: 0.8360\n",
            "Epoch 9/15\n",
            "2250/2250 [==============================] - 95s 42ms/step - loss: 0.1780 - accuracy: 0.9404 - val_loss: 0.9760 - val_accuracy: 0.8516\n",
            "Epoch 10/15\n",
            "2250/2250 [==============================] - 93s 42ms/step - loss: 0.1630 - accuracy: 0.9500 - val_loss: 0.9621 - val_accuracy: 0.8168\n",
            "Epoch 11/15\n",
            "2250/2250 [==============================] - 96s 43ms/step - loss: 0.1417 - accuracy: 0.9596 - val_loss: 0.9581 - val_accuracy: 0.8172\n",
            "Epoch 12/15\n",
            "2250/2250 [==============================] - 94s 42ms/step - loss: 0.1218 - accuracy: 0.9668 - val_loss: 1.7596 - val_accuracy: 0.8412\n",
            "Epoch 13/15\n",
            "2250/2250 [==============================] - 93s 42ms/step - loss: 0.1016 - accuracy: 0.9733 - val_loss: 1.2429 - val_accuracy: 0.8368\n",
            "Epoch 14/15\n",
            "2250/2250 [==============================] - 94s 42ms/step - loss: 0.0859 - accuracy: 0.9799 - val_loss: 1.3512 - val_accuracy: 0.8308\n",
            "Epoch 15/15\n",
            "2250/2250 [==============================] - 94s 42ms/step - loss: 0.0934 - accuracy: 0.9795 - val_loss: 2.2198 - val_accuracy: 0.8032\n"
          ]
        }
      ]
    }
  ]
}